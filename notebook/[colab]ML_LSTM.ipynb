{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "name": "ML_LSTM_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hqDyGONjScI",
        "outputId": "ddb5f259-5434-4561-e607-4d2211b774ad"
      },
      "source": [
        "!nvidia-smi"
      ],
      "id": "1hqDyGONjScI",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Feb 23 06:32:11 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOceJ-hVkQcu",
        "outputId": "ef6ff19c-2c13-4802-ba55-51827873fea9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "TOceJ-hVkQcu",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjiYAo2-kYEz",
        "outputId": "54491405-c56d-4bc8-853e-29169e5e1672"
      },
      "source": [
        "%cd 'drive/My Drive/Colab Notebooks/text_japanese/notebook/'\n",
        "!ls"
      ],
      "id": "wjiYAo2-kYEz",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/text_japanese/notebook\n",
            "mecab-ipadic-neologd  ML_w2v.ipynb    word_count.ipynb\n",
            "ML_BoW_tfi-df.ipynb   Untitled.ipynb  word_count_ngrams.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzJdS8AtjRBC",
        "outputId": "d3444195-b4c7-4e41-9573-6703c64c40d5"
      },
      "source": [
        "# https://qiita.com/jun40vn/items/78e33e29dce3d50c2df1\n",
        "\n",
        "# 形態素分析ライブラリーMeCab と 辞書(mecab-ipadic-NEologd)のインストール \n",
        "!apt-get -q -y install sudo file mecab libmecab-dev mecab-ipadic-utf8 git curl python-mecab > /dev/null\n",
        "!git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git > /dev/null \n",
        "!echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n > /dev/null 2>&1\n",
        "!pip install mecab-python3 > /dev/null\n",
        "\n",
        "# シンボリックリンクによるエラー回避\n",
        "!ln -s /etc/mecabrc /usr/local/etc/mecabrc"
      ],
      "id": "WzJdS8AtjRBC",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'mecab-ipadic-neologd' already exists and is not an empty directory.\n",
            "ln: failed to create symbolic link '/usr/local/etc/mecabrc': File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "incorporated-lecture"
      },
      "source": [
        "import os\n",
        "from copy import deepcopy\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "import MeCab"
      ],
      "id": "incorporated-lecture",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "id": "norwegian-diesel",
        "outputId": "0bc3e9e1-268f-433c-a97f-4132247ec8d6"
      },
      "source": [
        "df = pd.read_csv('../input/amazon_reviews_multilingual_JP_v1_00.tsv', sep='\\t')\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "id": "norwegian-diesel",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(262256, 15)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>marketplace</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>review_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_parent</th>\n",
              "      <th>product_title</th>\n",
              "      <th>product_category</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>helpful_votes</th>\n",
              "      <th>total_votes</th>\n",
              "      <th>vine</th>\n",
              "      <th>verified_purchase</th>\n",
              "      <th>review_headline</th>\n",
              "      <th>review_body</th>\n",
              "      <th>review_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>JP</td>\n",
              "      <td>65317</td>\n",
              "      <td>R33RSUD4ZTRKT7</td>\n",
              "      <td>B000001GBJ</td>\n",
              "      <td>957145596</td>\n",
              "      <td>SONGS FROM A SECRET GARDE</td>\n",
              "      <td>Music</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>残念ながら…</td>\n",
              "      <td>残念ながら…趣味ではありませんでした。ケルト音楽の範疇にも幅があるのですね…</td>\n",
              "      <td>2012-12-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>JP</td>\n",
              "      <td>65317</td>\n",
              "      <td>R2U1VB8GPZBBEH</td>\n",
              "      <td>B000YPWBQ2</td>\n",
              "      <td>904244932</td>\n",
              "      <td>鏡の中の鏡‾ペルト作品集(SACD)(Arvo Part:Spiegel im Spiegel)</td>\n",
              "      <td>Music</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>残念ながら…</td>\n",
              "      <td>残念ながら…趣味ではありませんでした。正直退屈…眠気も起きない…</td>\n",
              "      <td>2012-12-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>JP</td>\n",
              "      <td>65696</td>\n",
              "      <td>R1IBRCJPPGWVJW</td>\n",
              "      <td>B0002E5O9G</td>\n",
              "      <td>108978277</td>\n",
              "      <td>Les Miserables 10th Anniversary Concert</td>\n",
              "      <td>Music</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>ドリームキャスト</td>\n",
              "      <td>素晴らしいパフォーマンス。ミュージカル映画版の物足りない歌唱とは違います。</td>\n",
              "      <td>2013-03-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>JP</td>\n",
              "      <td>67162</td>\n",
              "      <td>RL02CW5XLYONU</td>\n",
              "      <td>B00004SRJ5</td>\n",
              "      <td>606528497</td>\n",
              "      <td>It Takes a Nation of Millions to Hold Us Back</td>\n",
              "      <td>Music</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>やっぱりマスト</td>\n",
              "      <td>専門的な事を言わずにお勧めレコメを書きたいのですが、文才が無いので無理でした。ヒップホップが...</td>\n",
              "      <td>2013-08-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>JP</td>\n",
              "      <td>67701</td>\n",
              "      <td>R2LA2SS3HU3A3L</td>\n",
              "      <td>B0093H8H8I</td>\n",
              "      <td>509738390</td>\n",
              "      <td>Intel CPU Core I3-3225 3.3GHz 3MBキャッシュ LGA1155...</td>\n",
              "      <td>PC</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>コスパ的には十分</td>\n",
              "      <td>今までの環境（Core2 Duo E4600)に比べれば十分に快適になりました。&lt;br /&gt;...</td>\n",
              "      <td>2013-02-10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  marketplace  ...  review_date\n",
              "0          JP  ...   2012-12-05\n",
              "1          JP  ...   2012-12-05\n",
              "2          JP  ...   2013-03-02\n",
              "3          JP  ...   2013-08-11\n",
              "4          JP  ...   2013-02-10\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "polar-spray"
      },
      "source": [
        "# tokenizer作成\n",
        "- 品詞を限定して、分かち書きした、単語のリストを返す"
      ],
      "id": "polar-spray"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bored-jones"
      },
      "source": [
        "path = \"-d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\"\n",
        "tagger = MeCab.Tagger(f\"-Ochasen {path}\")\n",
        "def tokenize(text, target=['名詞', '動詞']):\n",
        "        # 連結リスト\n",
        "        node = tagger.parseToNode(text)\n",
        "\n",
        "        result = []\n",
        "        while node:\n",
        "            hinshi = node.feature.split(\",\")[0]\n",
        "            if hinshi in target:\n",
        "                result.append(node.feature.split(\",\")[6])\n",
        "            node = node.next\n",
        "\n",
        "        return result"
      ],
      "id": "bored-jones",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "union-ground",
        "outputId": "d3a983cc-f008-42de-f3cb-fdd959987392"
      },
      "source": [
        "# 確認\n",
        "text = '私は今日パンを食べました。'\n",
        "print(tagger.parse(text))"
      ],
      "id": "union-ground",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "私\tワタシ\t私\t名詞-代名詞-一般\t\t\n",
            "は\tハ\tは\t助詞-係助詞\t\t\n",
            "今日\tキョウ\t今日\t名詞-副詞可能\t\t\n",
            "パン\tパン\tパン\t名詞-一般\t\t\n",
            "を\tヲ\tを\t助詞-格助詞-一般\t\t\n",
            "食べ\tタベ\t食べる\t動詞-自立\t一段\t連用形\n",
            "まし\tマシ\tます\t助動詞\t特殊・マス\t連用形\n",
            "た\tタ\tた\t助動詞\t特殊・タ\t基本形\n",
            "。\t。\t。\t記号-句点\t\t\n",
            "EOS\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "protective-legislature",
        "outputId": "07e8c9fc-0afe-4bdc-da7d-fdf6cd242768"
      },
      "source": [
        "tokenize(text)"
      ],
      "id": "protective-legislature",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['私', '今日', 'パン', '食べる']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cheap-approach"
      },
      "source": [
        "## 前処理"
      ],
      "id": "cheap-approach"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bibliographic-citation"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def clean_html(text, strip=True):\n",
        "    soup = BeautifulSoup(text, 'html.parser')\n",
        "    text = soup.get_text(strip=strip)\n",
        "    return text"
      ],
      "id": "bibliographic-citation",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "verbal-invite"
      },
      "source": [
        "import re\n",
        "def nornalize_number(text):\n",
        "    text = re.sub(r'\\d+', '0', text)\n",
        "    return text"
      ],
      "id": "verbal-invite",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "norwegian-shepherd"
      },
      "source": [
        "with open('../input/stopwords_slothlib.txt', 'r') as f:\n",
        "    stopwords = [w.strip() for w in f]\n",
        "    stopwords = set(stopwords)\n",
        "\n",
        "add_stopwords = {\n",
        "    '*',\n",
        "    'あ','い','う','え','お',\n",
        "    'か','き','く','け','こ',\n",
        "    'さ','し','す','せ','そ',\n",
        "    'た','ち','つ','て','と',\n",
        "    'な','に','ぬ','ね','の',\n",
        "    'は','ひ','ふ','へ','ほ',\n",
        "    'ま','み','む','め','も',\n",
        "    'や','ゆ','よ',\n",
        "    'わ' ,'を','ん'\n",
        "}\n",
        "stopwords = stopwords | add_stopwords\n",
        "\n",
        "def remove_stopwords(words):\n",
        "    words = [w for w in words if w not in stopwords]\n",
        "    return words"
      ],
      "id": "norwegian-shepherd",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "growing-leather"
      },
      "source": [
        "## ML\n",
        "- 評価値を予測するモデルを作成\n",
        "- ただし、5段階あって、３は判断が難しいので、今回は除き、\n",
        "    - {1, 2} -> 0, {4, 5}->1とする2値分類モデルを作成する"
      ],
      "id": "growing-leather"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "defensive-colon"
      },
      "source": [
        "## 1. データ準備"
      ],
      "id": "defensive-colon"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "virtual-louisville",
        "outputId": "72affd1f-b6dd-474b-c40a-ead8c8323bf5"
      },
      "source": [
        "df.head()"
      ],
      "id": "virtual-louisville",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>marketplace</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>review_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_parent</th>\n",
              "      <th>product_title</th>\n",
              "      <th>product_category</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>helpful_votes</th>\n",
              "      <th>total_votes</th>\n",
              "      <th>vine</th>\n",
              "      <th>verified_purchase</th>\n",
              "      <th>review_headline</th>\n",
              "      <th>review_body</th>\n",
              "      <th>review_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>JP</td>\n",
              "      <td>65317</td>\n",
              "      <td>R33RSUD4ZTRKT7</td>\n",
              "      <td>B000001GBJ</td>\n",
              "      <td>957145596</td>\n",
              "      <td>SONGS FROM A SECRET GARDE</td>\n",
              "      <td>Music</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>残念ながら…</td>\n",
              "      <td>残念ながら…趣味ではありませんでした。ケルト音楽の範疇にも幅があるのですね…</td>\n",
              "      <td>2012-12-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>JP</td>\n",
              "      <td>65317</td>\n",
              "      <td>R2U1VB8GPZBBEH</td>\n",
              "      <td>B000YPWBQ2</td>\n",
              "      <td>904244932</td>\n",
              "      <td>鏡の中の鏡‾ペルト作品集(SACD)(Arvo Part:Spiegel im Spiegel)</td>\n",
              "      <td>Music</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>残念ながら…</td>\n",
              "      <td>残念ながら…趣味ではありませんでした。正直退屈…眠気も起きない…</td>\n",
              "      <td>2012-12-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>JP</td>\n",
              "      <td>65696</td>\n",
              "      <td>R1IBRCJPPGWVJW</td>\n",
              "      <td>B0002E5O9G</td>\n",
              "      <td>108978277</td>\n",
              "      <td>Les Miserables 10th Anniversary Concert</td>\n",
              "      <td>Music</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>ドリームキャスト</td>\n",
              "      <td>素晴らしいパフォーマンス。ミュージカル映画版の物足りない歌唱とは違います。</td>\n",
              "      <td>2013-03-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>JP</td>\n",
              "      <td>67162</td>\n",
              "      <td>RL02CW5XLYONU</td>\n",
              "      <td>B00004SRJ5</td>\n",
              "      <td>606528497</td>\n",
              "      <td>It Takes a Nation of Millions to Hold Us Back</td>\n",
              "      <td>Music</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>やっぱりマスト</td>\n",
              "      <td>専門的な事を言わずにお勧めレコメを書きたいのですが、文才が無いので無理でした。ヒップホップが...</td>\n",
              "      <td>2013-08-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>JP</td>\n",
              "      <td>67701</td>\n",
              "      <td>R2LA2SS3HU3A3L</td>\n",
              "      <td>B0093H8H8I</td>\n",
              "      <td>509738390</td>\n",
              "      <td>Intel CPU Core I3-3225 3.3GHz 3MBキャッシュ LGA1155...</td>\n",
              "      <td>PC</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>コスパ的には十分</td>\n",
              "      <td>今までの環境（Core2 Duo E4600)に比べれば十分に快適になりました。&lt;br /&gt;...</td>\n",
              "      <td>2013-02-10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  marketplace  ...  review_date\n",
              "0          JP  ...   2012-12-05\n",
              "1          JP  ...   2012-12-05\n",
              "2          JP  ...   2013-03-02\n",
              "3          JP  ...   2013-08-11\n",
              "4          JP  ...   2013-02-10\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arranged-factor"
      },
      "source": [
        "# 3を除く\n",
        "df = df[df['star_rating']!=3]\n",
        "\n",
        "# 2値にマッピング\n",
        "star_rating_mapping = {1:0, 2:0, 4:1, 5:1}\n",
        "df['star_rating'] = df['star_rating'].replace(star_rating_mapping)"
      ],
      "id": "arranged-factor",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "religious-portrait",
        "outputId": "b272b50c-9886-4703-b42e-63c87cefb05a"
      },
      "source": [
        "# 確認\n",
        "df['star_rating'] .value_counts(dropna=False)"
      ],
      "id": "religious-portrait",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    208327\n",
              "0     25901\n",
              "Name: star_rating, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "painted-thread"
      },
      "source": [
        "import string\n",
        "\n",
        "def filter_by_ascii_rate(text, threshold=0.9):\n",
        "    \"\"\"テキスト中のアルファベットの割合が閾値以上のものをフィルター\"\"\"\n",
        "    ascii_letters = set(string.printable)\n",
        "    rate = sum(c in ascii_letters for c in text) / len(text)\n",
        "    return rate<threshold"
      ],
      "id": "painted-thread",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sunset-stations",
        "outputId": "26898d78-b715-4580-8915-bfa25ac932cd"
      },
      "source": [
        "# 日本語レビューだけ抽出\n",
        "df = df[df['review_body'].apply(filter_by_ascii_rate)]\n",
        "print(df.shape)"
      ],
      "id": "sunset-stations",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(228826, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "technical-dover"
      },
      "source": [
        "X = df['review_body']\n",
        "y = df['star_rating']"
      ],
      "id": "technical-dover",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laughing-guinea"
      },
      "source": [
        "## 2. Tokenization"
      ],
      "id": "laughing-guinea"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "improved-guidance",
        "outputId": "a0dd5507-3d19-4612-d29a-0080a4d3e2cf"
      },
      "source": [
        "%%time\n",
        "# 前処理+tokenization\n",
        "X = [tokenize(nornalize_number(clean_html(text)), target=['名詞']) for text in X]\n",
        "\n",
        "# stopwordsの除去\n",
        "X_rm_stopwords = []\n",
        "for tokens in X:\n",
        "    X_rm_stopwords.append([w for w in tokens if w not in stopwords])\n",
        "\n",
        "# スペース区切りの分かち書きの状態にする\n",
        "# 多くのMLモデルは、英字をベースにしたもので、入力はスペース区切りを求められるので\n",
        "X = [' '.join(tokens) for tokens in X_rm_stopwords]"
      ],
      "id": "improved-guidance",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2min 2s, sys: 2.4 s, total: 2min 4s\n",
            "Wall time: 2min 9s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "warming-youth"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "id": "warming-youth",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "convinced-region"
      },
      "source": [
        "## 3. wordのインデックス化\n",
        "- 便利なので、kerasのTokenizerクラスを用いる"
      ],
      "id": "convinced-region"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "honest-version"
      },
      "source": [
        "from keras_preprocessing.text import Tokenizer\n",
        "\n",
        "# 英字のスペース区切りのtokenに分割するもの、wordのindex化も出来る\n",
        "# defaultで、いくつかの文字がfilterされることになっているので注意\n",
        "tokenizer = Tokenizer(oov_token='<UNK>')  # index化する際に、trainに含まれていない単語を置き換える文字を指定\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "vocab = tokenizer.word_index\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "id": "honest-version",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "separated-replica",
        "outputId": "cb08aad6-69e3-4a9c-c853-7bc5d435d775"
      },
      "source": [
        "X_train[0]"
      ],
      "id": "separated-replica",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7629, 2, 283, 7629]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diagnostic-channels",
        "outputId": "0b4d3c01-ecb6-4cb9-a8a6-e7af55ab39d9"
      },
      "source": [
        "# 確認\n",
        "text1 = ['私 昨日 りんご 食べる']\n",
        "text2 = ['私 昨日 みかん 食べる']\n",
        "tokenizer_test = Tokenizer(oov_token='<UNK>')\n",
        "tokenizer_test.fit_on_texts(text1)\n",
        "print(tokenizer_test.word_index)  # word_indexの辞書\n",
        "print(tokenizer_test.index_word)  # index_wordの辞書\n",
        "\n",
        "print(tokenizer_test.texts_to_sequences(text1))\n",
        "print(tokenizer_test.texts_to_sequences(text2))"
      ],
      "id": "diagnostic-channels",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'<UNK>': 1, '私': 2, '昨日': 3, 'りんご': 4, '食べる': 5}\n",
            "{1: '<UNK>', 2: '私', 3: '昨日', 4: 'りんご', 5: '食べる'}\n",
            "[[2, 3, 4, 5]]\n",
            "[[2, 3, 1, 5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "decimal-separate"
      },
      "source": [
        "## 4. padding\n",
        "- 入力系列長を揃える\n",
        "- これも便利なので、kerasを用いる"
      ],
      "id": "decimal-separate"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whole-angel",
        "outputId": "c4196c19-c190-41b0-8ecb-11ef29040a66"
      },
      "source": [
        "length_seq = [len(x) for x in X_train]\n",
        "print('max:', np.max(length_seq))\n",
        "print('min:', np.max(length_seq))\n",
        "print('mean:', np.mean(length_seq))\n",
        "print('median:', np.median(length_seq))\n",
        "print('95%tile::', np.percentile(length_seq, 95))"
      ],
      "id": "whole-angel",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max: 2901\n",
            "min: 2901\n",
            "mean: 33.34406205615645\n",
            "median: 22.0\n",
            "95%tile:: 99.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soviet-notification"
      },
      "source": [
        "from keras_preprocessing.sequence import pad_sequences\n",
        "\n",
        "MAX_LEN = 100\n",
        "X_train = pad_sequences(X_train, maxlen=MAX_LEN, padding='post', truncating='post', value=0)\n",
        "X_test = pad_sequences(X_test, maxlen=MAX_LEN, padding='post', truncating='post', value=0)\n",
        "\n",
        "# 上記でkerasでindex化したが、index=0は空いていて、それを<PAD>とする\n",
        "vocab['<PAD>'] = 0"
      ],
      "id": "soviet-notification",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ethical-import"
      },
      "source": [
        "## 5. word embedding\n",
        "- index化した各wordに対して、ベクトル表現を割り当てる\n",
        "- 東北大が学習した、200次元word2vec"
      ],
      "id": "ethical-import"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lonely-beach"
      },
      "source": [
        "import gensim\n",
        "model_dir = '../input/word2vec/entity_vector.model.bin'\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format(model_dir, binary=True)  # 元のファイルがbinゆえ、binary=True"
      ],
      "id": "lonely-beach",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utility-control",
        "outputId": "9f3b7552-52c7-4fda-dbd9-5614393d55f1"
      },
      "source": [
        "# 確認, [word]として括弧で囲んで使うこと\n",
        "model.most_similar('[理]')"
      ],
      "id": "utility-control",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('[道_(哲学)]', 0.8235698938369751),\n",
              " ('[阿頼耶識]', 0.7655605673789978),\n",
              " ('[仁]', 0.7653003931045532),\n",
              " ('識', 0.7435705661773682),\n",
              " ('[義]', 0.7394132614135742),\n",
              " ('[仏性]', 0.7296761274337769),\n",
              " ('[気]', 0.7294569611549377),\n",
              " ('[法_(仏教)]', 0.7293650507926941),\n",
              " ('[真如]', 0.7274267673492432),\n",
              " ('[唯識]', 0.7263726592063904)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "forced-preserve"
      },
      "source": [
        "def filter_embeddings(emb_model, vocab, dim, num_words=None):\n",
        "    \"\"\"\n",
        "    vocabに存在する単語だけをフィルタリングして、word x ベクトル次元の行列を返す\n",
        "    input:\n",
        "        emb_model: {word1: vector1, word2: vector2, ...}というwordとベクトルの辞書的なもの\n",
        "        vocab: {word1: 1, word2:　2, ...}というwordとindexの辞書的なもの\n",
        "        dim: ベクトル次元\n",
        "    \n",
        "    * <UNK>, <PAD>は今、すべて0に割り当てられている\n",
        "    \"\"\"\n",
        "    if not num_words:\n",
        "        num_words = len(vocab)\n",
        "    \n",
        "    _embeddings = np.zeros((num_words, dim))\n",
        "    for word in vocab:\n",
        "        if word in emb_model:\n",
        "            word_id = vocab[word]\n",
        "            if word_id >= num_words:\n",
        "                continue\n",
        "            _embeddings[word_id] = emb_model[word]\n",
        "    return _embeddings"
      ],
      "id": "forced-preserve",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "gorgeous-independence"
      },
      "source": [
        "embeddings = filter_embeddings(model, vocab, dim=200, num_words=None)"
      ],
      "id": "gorgeous-independence",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "linear-constitution",
        "outputId": "d283a2e1-0848-4009-b934-ef23f4f259bb"
      },
      "source": [
        "embeddings.shape"
      ],
      "id": "linear-constitution",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105160, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "younger-latter"
      },
      "source": [
        "## 6. Model_2\n",
        "- NN\n",
        "- datasetクラス作成\n",
        "- modelクラス作成\n",
        "- trainループ作成"
      ],
      "id": "younger-latter"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scheduled-destiny"
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset"
      ],
      "id": "scheduled-destiny",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wssrdNKClOSo"
      },
      "source": [
        "import random\n",
        "\n",
        "def seed_everything(seed: int):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "seed_everything(1234)"
      ],
      "id": "wssrdNKClOSo",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0EbXOJslS49",
        "outputId": "21bc3e4a-a70f-4959-b599-e6a4eccd6a8c"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "#device = 'cpu'\n",
        "print(device)"
      ],
      "id": "M0EbXOJslS49",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "accompanied-public"
      },
      "source": [
        "class NNDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.X[idx]\n",
        "        label = self.y[idx]\n",
        "        return text, label"
      ],
      "id": "accompanied-public",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "applied-relief"
      },
      "source": [
        "X_train_tt = torch.tensor(X_train, dtype=torch.long).to(device)  # indexはlong型に\n",
        "X_test_tt = torch.tensor(X_test, dtype=torch.long).to(device)\n",
        "y_train_tt = torch.tensor(y_train.values, dtype=torch.float).to(device)  # BCELossを使うために、float型に\n",
        "y_test_tt = torch.tensor(y_test.values, dtype=torch.float).to(device)"
      ],
      "id": "applied-relief",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trying-impact"
      },
      "source": [
        "train_dataset = NNDataset(X_train_tt, y_train_tt)\n",
        "test_dataset = NNDataset(X_test_tt, y_test_tt)"
      ],
      "id": "trying-impact",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "presidential-diversity"
      },
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, drop_last=False)"
      ],
      "id": "presidential-diversity",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "transparent-harmony",
        "outputId": "c94f942f-3a87-4c7f-f774-da903c11dfab"
      },
      "source": [
        "# 確認\n",
        "for X, y in train_loader:\n",
        "    print(X.shape)\n",
        "    print(y.shape)\n",
        "    break"
      ],
      "id": "transparent-harmony",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 100])\n",
            "torch.Size([128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "comfortable-smell"
      },
      "source": [
        "class NNModel(nn.Module):\n",
        "    def __init__(self, embeddings):\n",
        "        super(NNModel, self).__init__()\n",
        "        self.model_name = 'NNModel'\n",
        "        \n",
        "        self.num_words, self.dim = embeddings.shape\n",
        "        self.embedding = nn.Embedding(self.num_words, self.dim)\n",
        "        self.embedding.weight = nn.Parameter(torch.tensor(embeddings, dtype=torch.float32))\n",
        "        self.embedding.weight.required_grad = False  # 重み固定\n",
        "        \n",
        "        # batch_first=True: (batch, seq, feature)\n",
        "        self.lstm = nn.LSTM(input_size=self.dim, hidden_size=128, num_layers=2, dropout=0.1, bidirectional=True, batch_first=True,)\n",
        "        self.fc = nn.Linear(128*2, 1)  # bidirectionalで、*2\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x =self.embedding(x)  # (batch, seq, dim)\n",
        "        x, _ = self.lstm(x)  # (batch, seq, dim)\n",
        "        x = self.fc(x[:,-1,:])  # seqの終端部分だけ抽出\n",
        "        return x.squeeze()"
      ],
      "id": "comfortable-smell",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "latin-throw",
        "outputId": "389e7267-6ec3-4cad-81f8-002fe7c68b2c"
      },
      "source": [
        "# 確認\n",
        "model = NNModel(embeddings).to(device)\n",
        "for x, y in train_loader:\n",
        "    print(model(x))\n",
        "    print(model(x).shape)\n",
        "    break"
      ],
      "id": "latin-throw",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.0095, -0.0086, -0.0115, -0.0081, -0.0123, -0.0105, -0.0118, -0.0103,\n",
            "        -0.0095, -0.0093, -0.0131, -0.0107, -0.0087, -0.0083, -0.0063, -0.0087,\n",
            "        -0.0069, -0.0109, -0.0193, -0.0089, -0.0097, -0.0092, -0.0104, -0.0085,\n",
            "        -0.0084, -0.0116, -0.0101, -0.0116, -0.0113, -0.0089, -0.0101, -0.0082,\n",
            "        -0.0111, -0.0114,  0.0536, -0.0102, -0.0109, -0.0098, -0.0053, -0.0104,\n",
            "        -0.0099, -0.0104,  0.0088, -0.0101, -0.0095, -0.0113, -0.0100, -0.0304,\n",
            "        -0.0103, -0.0094, -0.0085, -0.0088, -0.0092, -0.0107, -0.0101, -0.0085,\n",
            "        -0.0078, -0.0103, -0.0092, -0.0119, -0.0087, -0.0094, -0.0108, -0.0089,\n",
            "        -0.0094, -0.0094, -0.0086, -0.0113, -0.0081, -0.0096, -0.0105, -0.0106,\n",
            "        -0.0110, -0.0100, -0.0096, -0.0087, -0.0092, -0.0093, -0.0111, -0.0112,\n",
            "        -0.0085, -0.0092, -0.0109, -0.0092, -0.0102, -0.0114, -0.0109, -0.0085,\n",
            "        -0.0082, -0.0103, -0.0103,  0.0470, -0.0094, -0.0100, -0.0105, -0.0111,\n",
            "        -0.0118, -0.0086, -0.0083, -0.0066, -0.0087, -0.0118, -0.0104, -0.0104,\n",
            "        -0.0107, -0.0091, -0.0113, -0.0104, -0.0092, -0.0122, -0.0109, -0.0085,\n",
            "        -0.0092,  0.0393, -0.0081, -0.0092, -0.0085, -0.0106, -0.0089, -0.0093,\n",
            "        -0.0085, -0.0114, -0.0094, -0.0095, -0.0106, -0.0093, -0.0093, -0.0107],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "torch.Size([128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "still-mystery"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def train_model(train_loader, model, criterion, optimizer):\n",
        "    model.train()\n",
        "\n",
        "    batch_size = len(train_loader)\n",
        "    avg_loss = 0.\n",
        "    for X, y in tqdm(train_loader):\n",
        "        pred = model(X)\n",
        "        loss = criterion(pred, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        avg_loss += loss.item() / batch_size\n",
        "     \n",
        "    return avg_loss\n",
        "\n",
        "\n",
        "def valid_model(valid_loader, model, criterion):\n",
        "    model.eval()\n",
        "    \n",
        "    batch_size = len(valid_loader)\n",
        "    avg_loss = 0.\n",
        "    avg_score = 0.\n",
        "    with torch.no_grad():\n",
        "        for X, y in tqdm(valid_loader):\n",
        "            pred = model(X)            \n",
        "            loss = criterion(pred, y)\n",
        "            score = roc_auc_score(y.deteach().cpu().numpy(), pred.deteach().cpu().numpy())\n",
        "            \n",
        "            avg_loss += loss.item() / batch_size\n",
        "            avg_score += score / batch_size\n",
        "     \n",
        "    return avg_loss, avg_score"
      ],
      "id": "still-mystery",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "competent-difference",
        "outputId": "63672aa6-d6af-4395-b5f6-1cfc7f2b2678"
      },
      "source": [
        "%%time\n",
        "model = NNModel(embeddings).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss()  # 内部でsigmoidを持つ\n",
        "\n",
        "loss_train_list = []\n",
        "loss_best = 100\n",
        "EPOCHS = 20\n",
        "PATIENCE = 3\n",
        "for epoch in range(EPOCHS):\n",
        "    loss_train = train_model(train_loader, model, criterion, optimizer)\n",
        "    loss_train_list.append(loss_train)\n",
        "    \n",
        "    # lossが収束するまで続ける\n",
        "    if loss_train < loss_best:\n",
        "        loss_best = loss_train\n",
        "        best_weight = deepcopy(model.state_dict())\n",
        "        patience = 0\n",
        "    else:\n",
        "        patience += 1\n",
        "        if patience > PATIENCE:\n",
        "            break\n",
        "\n",
        "plt.plot(range(len(loss_train_list)), loss_train_list)\n",
        "plt.show()"
      ],
      "id": "competent-difference",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1430/1430 [01:07<00:00, 21.12it/s]\n",
            "100%|██████████| 1430/1430 [01:10<00:00, 20.33it/s]\n",
            "100%|██████████| 1430/1430 [01:10<00:00, 20.39it/s]\n",
            "100%|██████████| 1430/1430 [01:10<00:00, 20.38it/s]\n",
            "100%|██████████| 1430/1430 [01:09<00:00, 20.44it/s]\n",
            "100%|██████████| 1430/1430 [01:10<00:00, 20.42it/s]\n",
            "100%|██████████| 1430/1430 [01:10<00:00, 20.38it/s]\n",
            "100%|██████████| 1430/1430 [01:10<00:00, 20.41it/s]\n",
            "100%|██████████| 1430/1430 [01:10<00:00, 20.36it/s]\n",
            "100%|██████████| 1430/1430 [01:10<00:00, 20.38it/s]\n",
            "100%|██████████| 1430/1430 [01:09<00:00, 20.43it/s]\n",
            "100%|██████████| 1430/1430 [01:09<00:00, 20.45it/s]\n",
            "100%|██████████| 1430/1430 [01:09<00:00, 20.48it/s]\n",
            "100%|██████████| 1430/1430 [01:09<00:00, 20.48it/s]\n",
            "100%|██████████| 1430/1430 [01:09<00:00, 20.44it/s]\n",
            "100%|██████████| 1430/1430 [01:10<00:00, 20.43it/s]\n",
            "100%|██████████| 1430/1430 [01:10<00:00, 20.41it/s]\n",
            "100%|██████████| 1430/1430 [01:10<00:00, 20.41it/s]\n",
            "100%|██████████| 1430/1430 [01:10<00:00, 20.34it/s]\n",
            "100%|██████████| 1430/1430 [01:09<00:00, 20.44it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 16min 37s, sys: 6min 20s, total: 22min 58s\n",
            "Wall time: 23min 19s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brilliant-somalia",
        "outputId": "286ad191-8e51-4ec1-9735-3f6b1bdc59b6"
      },
      "source": [
        "model = NNModel(embeddings).to(device)\n",
        "model.load_state_dict(best_weight)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    pred_list = []\n",
        "    for X, y in tqdm(test_loader):\n",
        "        pred = model(X)\n",
        "        pred_list.extend(F.sigmoid(pred).detach().cpu().numpy())\n",
        "\n",
        "y_pred = [1 if p>=0.5 else 0 for p in pred_list]\n",
        "score = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print('')\n",
        "print(f'acc(LSTM): {score:.3f}')"
      ],
      "id": "brilliant-somalia",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/358 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "100%|██████████| 358/358 [00:03<00:00, 96.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "acc(LSTM): 0.891\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "informational-fairy"
      },
      "source": [
        ""
      ],
      "id": "informational-fairy",
      "execution_count": null,
      "outputs": []
    }
  ]
}
